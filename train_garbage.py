import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os

# è·¯å¾‘ï¼šæ›æˆä½ è‡ªå·±çš„è³‡æ–™å¤¾
DATASET_DIR = "/home/yoon/Downloads/Garbage classification/"

# åƒæ•¸
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 15   # CPU å»ºè­° 10~20ï¼Œè¶Šé«˜è¶Šæº–

# 1ï¸âƒ£ è³‡æ–™å‰è™•ç†èˆ‡å¢å¼·
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    DATASET_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    DATASET_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

# 2ï¸âƒ£ è¼‰å…¥ MobileNetV2ï¼ˆä¸åŒ…å«é ‚å±¤ï¼‰
base_model = MobileNetV2(weights='imagenet', include_top=False,
                         input_shape=(IMG_SIZE, IMG_SIZE, 3))

base_model.trainable = False  # å…ˆå‡çµç‰¹å¾µExtractorï¼ŒåŠ é€Ÿè¨“ç·´

# 3ï¸âƒ£ å»ºç«‹åˆ†é¡é ­
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
output_layer = Dense(train_generator.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output_layer)

# 4ï¸âƒ£ ç·¨è­¯æ¨¡å‹
model.compile(optimizer=Adam(1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 5ï¸âƒ£ é–‹å§‹è¨“ç·´
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS
)

# ===============================
# â­ åŠ å…¥æ··æ·†çŸ©é™£ï¼ˆæ”¾åœ¨é€™è£¡ï¼‰
# ===============================
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

print("[INFO] generating confusion matrix...")

# å–å¾—é©—è­‰è³‡æ–™çš„çœŸå¯¦æ¨™ç±¤
val_generator.reset()
valX, valY = [], []

for _ in range(len(val_generator)):
    x_batch, y_batch = val_generator.next()
    valX.append(x_batch)
    valY.append(y_batch)

valX = np.vstack(valX)
valY = np.vstack(valY)

# æ¨¡å‹é æ¸¬
y_pred = model.predict(valX)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true = np.argmax(valY, axis=1)

# æ··æ·†çŸ©é™£
cm = confusion_matrix(y_true, y_pred_labels)

classNames = list(train_generator.class_indices.keys())

print("\nClassification Report:\n")
print(classification_report(y_true, y_pred_labels, target_names=classNames))

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=classNames,
            yticklabels=classNames)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# ===============================
# 6ï¸âƒ£ å„²å­˜æ¨¡å‹
# ===============================
model.save("garbage_mobilenetv2.h5")
print("âœ… è¨“ç·´å®Œæˆï¼Œæ¨¡å‹å·²å„²å­˜ç‚º garbage_mobilenetv2.h5")

# 7ï¸âƒ£ å„²å­˜é¡åˆ¥åç¨±
import json
with open("classes.json", "w") as f:
    json.dump(train_generator.class_indices, f)
print("ğŸ“„ é¡åˆ¥ç´¢å¼•å·²å„²å­˜ç‚º classes.json")
